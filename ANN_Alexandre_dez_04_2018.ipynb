{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ucfilho/ANN_capstone_projects/blob/master/ANN_Alexandre_dez_04_2018.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "I22S4POjDEoo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Import libraries and modules, and defining needed functions\n",
        "\n",
        "from sklearn.neural_network import MLPRegressor   # sci-kit learn is a very used library for ANN consisting in classification problems or regression problems, and other machine learning problems.\n",
        "import random     # FOR MORE INFO: -> https://docs.python.org/3/library/random.html\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "#import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C6z_ZnJ9DFUA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f982325c-170b-4819-9eaf-79c0649a5585"
      },
      "cell_type": "code",
      "source": [
        "# ANN reproduction of the article : Biohydrogen production by batch indoor and outdoor photo-fermentation with\n",
        "# an immobilized consortium: A process model with Neural Networks . Monroy et al 2018.\n",
        "\n",
        "#Mechanistic models can be very useful since they provide simulated kinetics of substrate,\n",
        "#biomass and product concentration through the process time, and allow creating databases\n",
        "#for further applications. Nonetheless, they present some disadvantages such as the inability\n",
        "#to reproduce lag phases, metabolic shifts or continuous changes in input variables, for\n",
        "#instance, solar radiation.\n",
        "\n",
        "#In comparison to these mathematical models, there are data-based models (considered as\n",
        "#black-box models) that can be constructed by applying Artificial Intelligence (AI)\n",
        "#techniques or machine learning (ML) methods, which act increasing the process\n",
        "#performance through experience recorded by data. Artificial Neural Networks (ANN) is in\n",
        "#fact the most popular ML algorithm in process engineering, also considered as a pattern\n",
        "#recognition method [24].\n",
        "\n",
        "#ANN algorithm has been documented as a bioprocess modeling technique managed without\n",
        "#prior knowledge of the metabolic kinetics within the biological system [25]. In this sense,\n",
        "#some authors have reported the use of ANN-based models for anaerobic digestion [26,27]\n",
        "#and dark fermentation process [28-34] with high correlations between observed and\n",
        "#predicted data; however, its application has not been reported for photo-fermentation\n",
        "#modeling.\n",
        "\n",
        "\n",
        "#This work addresses the ANN application as a modeling technique to a group of several\n",
        "#experimental batches of photo-fermentation, carried out by an immobilized consortium of\n",
        "#photo-bacteria under different conditions of light intensity (I) using tungsten light, initial\n",
        "#pH, and concentrations of Fe, Mo and V.\n",
        "\n",
        "#ANN model was cross-validated, and the predicted kinetics were compared to the\n",
        "#experimental ones, as well as against the simulated kinetics produced by a mechanistic\n",
        "#model. The potential of the ANN algorithm was evaluated regarding its capacity to deliver\n",
        "#reliable predictions of hydrogen production by feeding information about sampling time,\n",
        "#light intensity, pH and metals (iron - Fe, Molybdenium - Mo and Vanadium - V) concentration added to the medium to the neural network.\n",
        "\n",
        "# for more information about the experiment, read the article.\n",
        "\n",
        "# the article compares a mechanistic model (mathematical equation) to the ANN model, to increase reliability.\n",
        "#The objective of this algorithm is to only reproduce the ANN model and to compare with the experimental results,\n",
        "#to see how good the ANN model predicted the experimental results.\n",
        "\n",
        "\n",
        "#The ANN model used in the article was used to predict the TOTAL ACCUMULATED HYDROGEN PRODUCED AT THE END OF THE SUBSTRATE CONSUMPTION (named H2), so the time was not an input data.\n",
        "#So the authors did lots of batches. But the authors could have done only one batch to make an ANN model to identify the dynamic effects of Hydrogen being produced along the time, and in\n",
        "#this case the time would be an input data to the ANN.\n",
        "\n",
        "\n",
        "#ANN can be recommended used to predict phenomena and to estimate a variable a value, when it is possible and cheap to make the experiments, or when it is worthy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Normalize(list):     # function to normalize the data contained in \"list\" to values between -1 and 1 and to store in a new list. input of this function must be a list.\n",
        "\n",
        "    list_max_orig = max(list)   # list's maximum element value before normalized\n",
        "    list_min_orig = min(list)    # list's minimum element value before normalized\n",
        "\n",
        "    a = (list_max_orig + list_min_orig)/2\n",
        "\n",
        "    b =  (list_max_orig - list_min_orig)/2\n",
        "\n",
        "    list_norm = []\n",
        "\n",
        "    for i in range(0,len(list)):   # increasing elements to the new normalized list\n",
        "\n",
        "        x_norm = (list[i] - a)/b      # normalized variable value between -1 and 1 of index \"i\"\n",
        "\n",
        "        list_norm.append(float(x_norm))\n",
        "\n",
        "    return list_norm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Original_value(before_normalized_list,normalized_list):     # function to make the normalized values, from a list (y_train of just one column!!, (only one dependent variable)), go back to its original value\n",
        "    #for the use of this function the before_normalized_list is the original list before being normalized. Generally, it will have more elements than the \"normalized_list\".\n",
        "    #the number of elements in comparison of these two lists, does not matter.\n",
        "    #this function is used only for y_train, because it does not make sense use it for x_train.\n",
        "\n",
        "\n",
        "    #normalized_list is the list obtained of y_train after the train is done.\n",
        "    #before_normalized_list is the list containing the experimental results.\n",
        "\n",
        "\n",
        "    list_max_orig = max(before_normalized_list)   # list's maximum element value before normalized\n",
        "    list_min_orig = min(before_normalized_list)    # list's minimum element value before normalized\n",
        "\n",
        "    a = (list_max_orig + list_min_orig)/2\n",
        "\n",
        "    b =  (list_max_orig - list_min_orig)/2\n",
        "\n",
        "    list_original = []\n",
        "\n",
        "    for i in range(0,len(normalized_list)):   # increasing elements to the new normalized list\n",
        "\n",
        "        x_norm = normalized_list[i]\n",
        "        x_original  =  a + b*x_norm #original value of x original before it was normalized\n",
        "        list_original.append(float(x_original))\n",
        "\n",
        "    return list_original\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_list(main_list,indice_list): #cria uma nova list derivada de uma list de entrada, onde os elementos puxados para a nova list, são os elementos que contém na velha list e são identificados de acordo com o indice requerido\n",
        "    # , onde os mesmos são especificados lista de indices.\n",
        "    #  indice_list não precisa ter a mesma dimensão de main_list.\n",
        "    new_list=[]\n",
        "    for i in range(len(indice_list)):\n",
        "        new_list.append(main_list[int(indice_list[i])])        # se o valor do indice de i for diferente\n",
        "\n",
        "    return new_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# This is a regression script to predict a phenomenon.\n",
        "## Table 1 data: experimental data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Fe = [2.8, 2.8, 2.8, 2.8, 11, 11, 11, 0, 13.8, 6.9, 6.9, 6.9, 6.9, 6.9,0 ,0, 0, 0, 0, 0, 0, 0, 0, 0,11, 6.9, 0, 0, 0,0]  # Medium's initial iron concentration in mg/L\n",
        "\n",
        "V = [0.13, 0.13, 0.51, 0.51, 0.13, 0.51,0.51, 0.32, 0.32, 0, 0.64, 0.32, 0.32, 0.32, 0 , 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.13, 0.32, 0, 0, 0, 0] # Medium's initial Vanadium concentration in mg/L\n",
        "\n",
        "Mo = [0.32, 1.26, 0.32, 1.26, 1.26, 0.32, 1.26, 0.79, 0.79, 0.79, 0.79, 0, 1.58, 0.79, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.32, 0.79, 0, 0, 0, 0] # Medium's initial Molybdenium concentration in mg/L\n",
        "\n",
        "I = [221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 221, 125.3, 125.3, 366.7, 246, 246, 75.3, 416.7, 246, 366.7, 221, 221, 221, 366.7, 246, 125.3] # Tungsten's light intensity in W/m^2. Kept constant during each batch.\n",
        "\n",
        "Initial_ph = [6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.5, 6.7, 7.7, 7.7, 6.5, 7.9, 7.2, 7.2, 7.2, 6.7, 6.5, 6.5, 6.5, 6.7, 7.2, 6.7] # Initial pH of the culture medium. Kept constant during each batch.\n",
        "\n",
        "H2 = [4194, 4433, 4447, 4327, 3105, 4265, 3372, 3926, 3348, 4397, 4209, 3463, 4387, 4186, 4393, 3965, 2970, 2845, 3977, 2269, 2620, 2229, 3795, 2991, 4626, 4023, 4075, 3327, 3475, 4100]  # Total accumulated biohydrogen in mL/L      . Each element of this arrays regards one of the batches.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Normalizing the data and storing in new lists, to enter in the ANN MLP (multi-layer perceptron) - which requires the normalization of the data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Fe_norm = Normalize(Fe)  # Normalizing Fe\n",
        "\n",
        "V_norm = Normalize(V)  # Normalizing V\n",
        "\n",
        "Mo_norm = Normalize(Mo)  # Normalizing Mo\n",
        "\n",
        "I_norm = Normalize(I)  # Normalizing I\n",
        "\n",
        "Initial_ph_norm = Normalize(Initial_ph) # Normalizing pH\n",
        "\n",
        "H2_norm = Normalize(H2)  # Normalizing H2\n",
        "\n",
        "\n",
        "y_norm = H2_norm   # valores normalizados da resposta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Training the ANN using .fit and .train and MLPRegressor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "population = 25   # número de elementos que deseja ser colocado na variável treino, deve ser menor ou igual ao tamanho de amostras.\n",
        "\n",
        "LISTA = []   #criando um indice para que cada variável da amostra estejam relacionados ao mesmo experimento.\n",
        "for i in range(len(y_norm)):\n",
        "    LISTA.append(i)\n",
        "indice = random.sample(LISTA,population) #creating a random list to train  # random.sample(population, k) -> Return a k length list of unique elements chosen from the population sequence or set. Used for random sampling without replacement.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Fe_train = create_list(Fe_norm,indice) # criando list de cada variavel para treino ou teste, já normalizadas\n",
        "V_train = create_list(V_norm,indice)\n",
        "Mo_train = create_list(Mo_norm,indice)\n",
        "I_train = create_list(I_norm,indice)\n",
        "Initial_ph_train = create_list(Initial_ph_norm,indice)\n",
        "H2_train = create_list(H2_norm,indice)\n",
        "\n",
        "Matrix_train = [Fe_train,V_train,Mo_train,I_train,Initial_ph_train]\n",
        "\n",
        "\n",
        "\n",
        "x_train = np.array(Matrix_train)\n",
        "y_train = np.array( H2_train )\n",
        "\n",
        "x_train = x_train.T  #transpondo a matriz, transformando linhas em colunas e colunas em linhas, pois o .fit do sklearn trabalha com a linha da matriz x_train sendo o valor da amostra no experimento.\n",
        "\n",
        "y_train = y_train.T\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Defining neural network - for more info: http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor\n",
        "\n",
        "clf = MLPRegressor(solver='lbfgs',activation='tanh',alpha=1e-5,hidden_layer_sizes=(6,9),random_state=1)  # clf is a short to \"classifier\", a term very used in machine learning\n",
        "\n",
        "\n",
        "# treinando a rede neural\n",
        "\n",
        "clf.fit(x_train, y_train)   #  o numero de linhas de x_train e y_train tem que ser equivalente ao numero do experimento, enquanto a coluna diz respeito ao numero de variaveis\n",
        "\n",
        "y_calc_rede_train = clf.predict(x_train)   #comando para calcular valor de y através de uma dada matriz x_train, depois que a rede já está treinada. Os valores sairão normalizados.\n",
        "\n",
        "y_calc_rede_train = Original_value(H2,y_calc_rede_train)  # retornando valores normalizados de y_calc_rede, para valores com escalas originais, que foram calculados a partir da rede neural.\n",
        "#o retorno dessa variável para valores originais é importante para calcular o R^2 do fit.\n",
        "\n",
        "\n",
        "\n",
        "# criando uma matriz com dados experimentais aleatorios para testar mais ainda a rede treinada e ver se o R^2 da rede está bom o suficiente como o desejável.\n",
        "\n",
        "\n",
        "population = 10\n",
        "indice = random.sample(LISTA,population) #creating a random list to train  # random.sample(population, k) -> Return a k length list of unique elements chosen from the population sequence or set. Used for random sampling without replacement.\n",
        "\n",
        "\n",
        "Fe_test = create_list(Fe_norm,indice) # criando list de cada variavel para treino ou teste, já normalizadas\n",
        "V_test = create_list(V_norm,indice)\n",
        "Mo_test = create_list(Mo_norm,indice)\n",
        "I_test = create_list(I_norm,indice)\n",
        "Initial_ph_test = create_list(Initial_ph_norm,indice)\n",
        "H2_test = create_list(H2_norm,indice)\n",
        "\n",
        "\n",
        "\n",
        "x_test = ( np.array([Fe_test,V_test,Mo_test,I_test,Initial_ph_test]) ).T  #\n",
        "y_test = (np.array(H2_test) ).T\n",
        "\n",
        "\n",
        "\n",
        "y_calc_rede_test = clf.predict(x_test)   # calculando valor de y pela rede neural\n",
        "#A rede seria perfeita R^2 = 1 se todos os valores de ycalc_rede_test fossem iguais aos valores dos elementos de H2_test! e também se o critério de não overfitting fosse satisfeito.\n",
        "\n",
        "y_calc_rede_test = Original_value(H2,y_calc_rede_test)\n",
        "\n",
        "\n",
        "# calculando o R^2\n",
        "H2_test = Original_value(H2,H2_test)\n",
        "\n",
        "mse =  mean_squared_error(H2_test,y_calc_rede_test)\n",
        "\n",
        "R2=r2_score(H2_test,y_calc_rede_test)\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "print(mse)\n",
        "print(R2)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9181.453488330444\n",
            "0.9830545600926927\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}